<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <title>PC</title>
    <style>
        #in {
            width: 640px;
            height: 360px;
        }
        #out {
            width: 640px;
            height: 360px;
        }
    </style>
</head>
<body>
<video autoplay id="in"></video>
<video autoplay id="out"></video>
<canvas id="canvas" width="640" height="360"></canvas>
<script type="module">
    import { initWebGl } from './setup-webgl.mjs';

    const [vs, fs] = await Promise.all([
        await fetch('vertex.glsl').then(r => r.text()),
        fetch('yuv-i420-cas.glsl').then(r => r.text()),
    ]);

    /**
     * @param {CanvasRenderingContext2D} ctx
     * @param {object} target
     * @returns {(function(*): void)} function to check if "target.catchFrame" was called and if so, store provided frame data
     */
    const canvas = document.getElementById('canvas');
    const gl = canvas.getContext('webgl2', { alpha: true, antialias: false, colorSpace: "srgb" });

    if (!gl) throw new Error('WebGL2 is not supported');

    const drawGl = initWebGl(gl, vs, fs);

    async function setupWebRTC(stream) {
        const [track] = stream.getVideoTracks();
        const pc1 = new RTCPeerConnection();
        window.pc1 = pc1;
        const pc2 = new RTCPeerConnection();
        window.pc2 = pc2;
        pc1.onicecandidate = e => pc2.addIceCandidate(e.candidate);
        pc2.onicecandidate = e => pc1.addIceCandidate(e.candidate);
        let resultResolver;
        const result = new Promise(resolve => {
            resultResolver = resolve;
        });
        pc2.ontrack = e => { resultResolver(new MediaStream([e.track])); }
        pc1.addTrack(track);
        const offer = await pc1.createOffer();
        await pc1.setLocalDescription(offer);
        await pc2.setRemoteDescription(offer);
        const answer = await pc2.createAnswer();
        await pc2.setLocalDescription(answer);
        await pc1.setRemoteDescription(answer);

        return result;
    }

    import { getRawFrames } from './get-raw-frames.mjs';
    const inStream = await navigator.mediaDevices.getUserMedia({ video: { width: 320, height: 180 }});
    window.in.srcObject = inStream;

    const outStream = await setupWebRTC(inStream);
    window.out.srcObject = outStream;

    let bufferSize = 0, format = '', view_y, view_uv;
    for await (const frameData of getRawFrames(outStream)) {
        if (bufferSize !== frameData.buffer.byteLength || format !== frameData.format) {
            bufferSize = frameData.buffer.byteLength;
            format = frameData.format;
            if (frameData.format !== 'I420') {
                alert(`Only I420 frames are supported but got ${format}!`);
                throw new Error('Invalid frame format');
            }
            view_y = new Uint8Array(frameData.buffer.buffer, 0, frameData.planes[1].offset);
            view_uv = new Uint8Array(frameData.buffer.buffer, frameData.planes[1].offset);
        }

        drawGl(frameData.visibleRect.width, frameData.visibleRect.height, view_y, view_uv, true);
    }
</script>
</body>
</html>